import os
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import pandas as pd
import pdb
from tqdm import tqdm

from torch.utils.data import DataLoader, Dataset
from torch.utils.tensorboard import SummaryWriter
from models import CSPBlock, ShuffleAttention, CameraYOLO
from dataset import RadarCameraYoloDataset
from utils import yolo_collate_fn, bbox_iou

# âœ… CUDA ê°•ì œ ë¹„í™œì„±í™” (GPU ì‚¬ìš© ê¸ˆì§€)
# os.environ["CUDA_VISIBLE_DEVICES"] = ""
# âœ… Model & Dataset Setup
# device = torch.device("cpu")

# os.environ["CUDA_VISIBLE_DEVICES"] = "0"

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# print(f"Current device: {device}")

# # í˜„ì¬ í™œì„±í™”ëœ GPU ì¸ë±ìŠ¤ ì¶œë ¥ (CUDA ì‚¬ìš© ì‹œ)
# if torch.cuda.is_available():
#     print(f"Device name: {torch.cuda.get_device_name(torch.cuda.current_device())}")

num_classes = 7
split_ratio = 0.7

# âœ… ê°•ì œ CPU ëª¨ë“œ
# device = torch.device("cpu")
# print("âš ï¸ Running on CPU mode only")

# YOLO Loss Function
class YOLOLoss(nn.Module):
    def __init__(self, num_classes):
        super(YOLOLoss, self).__init__()
        self.bce = nn.BCEWithLogitsLoss()
        self.bce_cls = nn.BCEWithLogitsLoss()
        self.l1 = nn.L1Loss()
        self.num_classes = num_classes

    def forward(self, preds, labels):
        B, N, _ = preds.shape
        
        # âœ… ì†ì‹¤ í…ì„œë¡œ ì´ˆê¸°í™” (requires_grad=True í•„ìˆ˜)
        total_loss = torch.tensor(0., device=preds.device, requires_grad=True)
        total_bbox_loss = torch.tensor(0., device=preds.device, requires_grad=True)
        total_obj_loss = torch.tensor(0., device=preds.device, requires_grad=True)
        total_class_loss = torch.tensor(0., device=preds.device, requires_grad=True)

        for i in range(B):
            if labels[i].numel() == 0:
                continue

            gt_classes = labels[i][:, 0].long()
            gt_bboxes = labels[i][:, 1:5]

            pred_bboxes = preds[i, :, :4]
            pred_obj = preds[i, :, 4]
            pred_cls = preds[i, :, 5:]

            # IoU ê¸°ë°˜ GT ë§¤ì¹­
            iou_matrix = bbox_iou(pred_bboxes, gt_bboxes)  # (N, M)
            best_iou, best_pred_idx = iou_matrix.max(dim=0)

            matched_preds = pred_bboxes[best_pred_idx]  # (M, 4)
            matched_obj = pred_obj[best_pred_idx]  # (M,)
            matched_cls = pred_cls[best_pred_idx]  # (M, num_classes)

            bbox_loss = self.l1(matched_preds, gt_bboxes)
            obj_loss = self.bce(matched_obj, best_iou.detach())

            # í´ë˜ìŠ¤ íƒ€ê²Ÿ ìƒì„±
            class_targets = torch.zeros_like(matched_cls)
            class_targets[range(gt_classes.shape[0]), gt_classes] = 1
            class_loss = self.bce(matched_cls, class_targets)

            # âœ… ì†ì‹¤ ëˆ„ì  (í…ì„œ ìƒíƒœ ìœ ì§€)
            total_bbox_loss += bbox_loss
            total_obj_loss += obj_loss
            total_class_loss += class_loss
            total_loss += bbox_loss + obj_loss + class_loss

        # âœ… floatë¡œ ë‚˜ëˆ„ê¸° (torch.tensorë¡œ ë³€í™˜ ê¸ˆì§€)
        total_loss = total_loss / float(B)
        total_bbox_loss = total_bbox_loss / float(B)
        total_obj_loss = total_obj_loss / float(B)
        total_class_loss = total_class_loss / float(B)

        # âœ… í…ì„œ ìƒíƒœ ë°˜í™˜
        return total_loss, total_bbox_loss, total_obj_loss, total_class_loss


# âœ… Training Function
def train_model(model, dataloader, criterion, optimizer, num_epochs, start_epoch=0, model_path=None):
    model.train()
    os.makedirs("output", exist_ok=True)  # ğŸ”¥ 'output' í´ë” ìƒì„± (ì—†ìœ¼ë©´ ìë™ ìƒì„±)
    writer = SummaryWriter("logs")  # ğŸ”¥ TensorBoard writer ìƒì„±

    # ğŸ”¥ ê¸°ì¡´ ëª¨ë¸ì´ ìˆìœ¼ë©´ ë¶ˆëŸ¬ì˜¤ê¸°
    if model_path and os.path.exists(model_path):
        model.load_state_dict(torch.load(model_path))
        print(f"âœ… Loaded model from {model_path}, resuming training from epoch {start_epoch}")

    for epoch in range(num_epochs):
        epoch_loss, epoch_bbox_loss, epoch_obj_loss, epoch_class_loss = 0, 0, 0, 0
        total_samples = 0  # ì „ì²´ ìƒ˜í”Œ ìˆ˜
        
        for images, radar, labels in tqdm(dataloader):
            batch_size = images.shape[0]  # í˜„ì¬ ë°°ì¹˜ í¬ê¸°
            total_samples += batch_size

            images = images.to(device)
            labels = [label.to(device) for label in labels]

            optimizer.zero_grad()
            outputs = model(images)
            loss, bbox_loss, obj_loss, class_loss = criterion(outputs, labels)
            # print(f"loss: {type(loss)}")
            loss.backward()
            
            optimizer.step()

            epoch_loss += loss.item() * batch_size
            epoch_bbox_loss += bbox_loss.item() * batch_size
            epoch_obj_loss += obj_loss.item() * batch_size
            epoch_class_loss += class_loss.item() * batch_size

        # ğŸ”¥ ì „ì²´ ìƒ˜í”Œ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ í‰ê·  Loss ê³„ì‚°
        avg_loss = epoch_loss / total_samples
        avg_bbox_loss = epoch_bbox_loss / total_samples
        avg_obj_loss = epoch_obj_loss / total_samples
        avg_class_loss = epoch_class_loss / total_samples

        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.8f}, "
              f"Bbox Loss: {epoch_bbox_loss:.8f}, "
              f"Obj Loss: {epoch_obj_loss:.8f}, "
              f"Class Loss: {avg_class_loss:.8f}")
        
        # ğŸ”¥ TensorBoardì— Loss ê¸°ë¡
        writer.add_scalar("Loss/Total", epoch_loss, epoch + 1)
        writer.add_scalar("Loss/BBox", epoch_bbox_loss, epoch + 1)
        writer.add_scalar("Loss/Objectness", epoch_obj_loss, epoch + 1)
        writer.add_scalar("Loss/Class", avg_class_loss, epoch + 1)
        
        # ğŸ”¥ 10 Epochë§ˆë‹¤ ëª¨ë¸ ì €ì¥ (output í´ë”ì— ì €ì¥)
        if (epoch + 1) % 10 == 0:
            model.eval()
            model_path = f"output/trained_model_epoch_{epoch+1}.pth"
            torch.save(model.state_dict(), model_path)
            print(f"âœ… Model saved at epoch {epoch+1} in {model_path}")
    
    writer.close()  # ğŸ”¥ TensorBoard writer ì¢…ë£Œ

model = CameraYOLO(num_classes=num_classes).to(device)
dataset = RadarCameraYoloDataset(data_root="/home/songhee/WaterScenes/waterscenes_dataset/")

train_size = int(split_ratio * len(dataset))
val_size = len(dataset) - train_size
train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=1, collate_fn=yolo_collate_fn)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=1, collate_fn=yolo_collate_fn)

learning_rate = 0.0005
criterion = YOLOLoss(num_classes)
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# âœ… í•™ìŠµ ë° ê²€ì¦ ë£¨í”„
print("--------------- Training Started! ---------------")
train_model(model, train_loader, criterion, optimizer, num_epochs=100)
print("--------------- Training Completed! ---------------")

# # âœ… í•™ìŠµ ì™„ë£Œ í›„ ëª¨ë¸ ì €ì¥
# model.eval()  # í‰ê°€ ëª¨ë“œë¡œ ë³€ê²½
# torch.save(model.state_dict(), "trained_model.pth")
# print("âœ… Model saved as trained_model.pth")
